{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322bd68c-9183-4021-acd1-cbe5befd541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run regression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5e3c2f-0af6-44c3-b3dc-14555343c024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74c55cf-f1cf-4185-bdb4-bc9c1045d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac8a17a-74ac-4810-9f31-dc408cef12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function calculate the r2 scores\n",
    "def evaluate_model(model_name, y_test, y_pred, is_scaled=False):\n",
    "    \"\"\"Calculate and print R2 scores for a model\"\"\"\n",
    "    r2_overall = r2_score(y_test, y_pred)\n",
    "    r2_weighted = r2_score(y_test, y_pred, multioutput=\"variance_weighted\")\n",
    "    \n",
    "    scale_note = \" (scaled)\" if is_scaled else \"\"\n",
    "    print(f\"\\n{model_name} Results{scale_note}:\")\n",
    "    print(f\"  Overall R2:  {r2_overall:.4f}\")\n",
    "    print(f\"  Weighted R2: {r2_weighted:.4f}\")\n",
    "    \n",
    "    return r2_overall, r2_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297605be-bb8c-45a7-9add-906fab324fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn_model(input_dim, output_dim, architecture='standard'):\n",
    "    \"\"\"Build a neural network model with specified architecture\"\"\"\n",
    "    \n",
    "    if architecture == 'standard':\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(input_dim,)),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(output_dim)\n",
    "        ])\n",
    "    elif architecture == 'wide':\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(input_dim,)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(output_dim)\n",
    "        ])\n",
    "    elif architecture == 'deep':\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(input_dim,)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(output_dim)\n",
    "        ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee66b598-e052-4c57-babb-f09a0c74c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, epochs=500, patience=30, verbose=0):\n",
    "    \"\"\"Train a model with early stopping and learning rate scheduling\"\"\"\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=patience,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=15,\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=epochs,\n",
    "        batch_size=128,\n",
    "        verbose=verbose,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33771f2a-7839-4940-a236-3019d1f4d7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(359999, 2)\n",
      "2 6\n"
     ]
    }
   ],
   "source": [
    "# prepare inverse data (nm -> V)\n",
    "# Input: current positions (x_out, z_out)\n",
    "# Output: voltage windows that led to those positions\n",
    "X_inverse = xz_data_out  # (N, 2) - positions\n",
    "y_inverse = xz_data_in   # (N, 6) - voltage windows\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_inverse, y_inverse, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "WINDOW_LEN = 3 # using the same window length as in regression\n",
    "print(X_inverse.shape)\n",
    "input_dim = X_inverse.shape[1]  # 2 (x and z positions)\n",
    "output_dim = y_inverse.shape[1]  # 6 (3 x-voltage + 3 z-voltage windows)\n",
    "print(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c03ea0cc-9cfc-4609-9b6e-85016992562a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Results:\n",
      "  Overall R2:  0.3770\n",
      "  Weighted R2: 0.3924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.37700707456416543, 0.39244021478839936)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "evaluate_model(\"Linear Regression\", y_test, y_pred_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c5a79-43b6-4963-9220-dd43401e64ef",
   "metadata": {},
   "source": [
    "The feedforward (voltage -> position) R2 score came out to **0.74** (which is good).\n",
    "The inverse of this (position -> voltage) gives us an R2 score of **0.39**. This means the inverse mapping is fundamentally harder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f3b5b-b022-4779-9cff-d8743f2c86fe",
   "metadata": {},
   "source": [
    "**APPROACH 1**\n",
    "\n",
    "Training a NN with just positions and predicting the voltage window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "982be725-0eb9-4b2e-939e-0815ee5ebbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Results (scaled):\n",
      "  Overall R2:  0.4227\n",
      "  Weighted R2: 0.4230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4226871685931764, 0.42301597475225305)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X_inverse)\n",
    "y_scaled = StandardScaler().fit_transform(y_inverse)\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = build_nn_model(X_train_scaled.shape[1], y_train_scaled.shape[1])\n",
    "history = train_model(model, X_train_scaled, y_train_scaled, verbose=0)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled, verbose=0)\n",
    "evaluate_model(\"Neural Network\", y_test_scaled, y_pred, is_scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9918e1-a245-416c-b740-960fc94b4e3e",
   "metadata": {},
   "source": [
    "**APPROACH 2**\n",
    "\n",
    "Create a feature vector containing the current state and previous 2 states\n",
    " \n",
    " `[ x(t−2), x(t−1), x(t), z(t−2), z(t−1), z(t) ]`\n",
    "\n",
    "This way the network has more information about the previous states - not just the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85745892-608c-4559-8ebd-d79bac6e1087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input (position only): (359999, 2)\n",
      "New input (position history): (359999, 6)\n"
     ]
    }
   ],
   "source": [
    "x_out = df[\"x_out\"].values.reshape(-1, 1)\n",
    "z_out = df[\"z_out\"].values.reshape(-1, 1)\n",
    "\n",
    "# create position windows...\n",
    "x_out_window = sliding_window_view(x_out, WINDOW_LEN, 0).squeeze()\n",
    "z_out_window = sliding_window_view(z_out, WINDOW_LEN, 0).squeeze()\n",
    "\n",
    "xz_out_window = np.concatenate([x_out_window, z_out_window], axis=1)\n",
    "\n",
    "print(f\"Original input (position only): {xz_data_out.shape}\")\n",
    "print(f\"New input (position history): {xz_out_window.shape}\")\n",
    "\n",
    "# Now input and output have same length and meaning\n",
    "X_inverse_history = xz_out_window  # (N, 6) - position windows\n",
    "y_inverse = xz_data_in             # (N, 6) - voltage windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6802d55-53a3-42db-bdcd-5c51b4abc024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Results:\n",
      "  Overall R2:  0.4847\n",
      "  Weighted R2: 0.4980\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_inverse_history, y_inverse, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "r2_lin, _ = evaluate_model(\"Linear Regression\", y_test, y_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acee69e2-ce4b-48d4-99f1-cba8dcd29fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Results (scaled):\n",
      "  Overall R2:  0.6352\n",
      "  Weighted R2: 0.6355\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "X_scaled = StandardScaler().fit_transform(X_inverse_history)\n",
    "y_scaled = StandardScaler().fit_transform(y_inverse)\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = build_nn_model(X_train_scaled.shape[1], y_train_scaled.shape[1])\n",
    "history = train_model(model, X_train_scaled, y_train_scaled, verbose=0)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled, verbose=0)\n",
    "r2_nn, _ = evaluate_model(\"Neural Network\", y_test_scaled, y_pred, is_scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab2666-dd73-4337-9888-5c3914f089d4",
   "metadata": {},
   "source": [
    "**APPROACH 3**\n",
    "\n",
    "Increase the size of the feature vector by adding velocity and acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab24d5c6-7437-4584-a773-8a64abd68f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(359999, 10)\n"
     ]
    }
   ],
   "source": [
    "# Calculate velocity and acceleration\n",
    "x_out_full = df[\"x_out\"].values\n",
    "z_out_full = df[\"z_out\"].values\n",
    "\n",
    "x_velocity = np.gradient(x_out_full)\n",
    "z_velocity = np.gradient(z_out_full)\n",
    "x_acceleration = np.gradient(x_velocity)\n",
    "z_acceleration = np.gradient(z_velocity)\n",
    "\n",
    "# Truncate to match window length\n",
    "x_vel_truncated = x_velocity[WINDOW_LEN-1:]\n",
    "z_vel_truncated = z_velocity[WINDOW_LEN-1:]\n",
    "x_acc_truncated = x_acceleration[WINDOW_LEN-1:]\n",
    "z_acc_truncated = z_acceleration[WINDOW_LEN-1:]\n",
    "\n",
    "X_inverse_history = np.column_stack([\n",
    "    xz_out_window,\n",
    "    x_vel_truncated,\n",
    "    z_vel_truncated,\n",
    "    x_acc_truncated,\n",
    "    z_acc_truncated\n",
    "])\n",
    "\n",
    "print(X_inverse_history.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3607b788-c73a-495c-98f3-f0f4ecdc2a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Results:\n",
      "  Overall R2:  0.4896\n",
      "  Weighted R2: 0.5027\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_inverse_history, y_inverse, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "r2_lin_, _ = evaluate_model(\"Linear Regression\", y_test, y_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bdbcf6c-f2a8-4eac-83d0-b46f93d19c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Results (scaled):\n",
      "  Overall R2:  0.9554\n",
      "  Weighted R2: 0.9554\n"
     ]
    }
   ],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X_inverse_history)\n",
    "y_scaled = StandardScaler().fit_transform(y_inverse)\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = build_nn_model(X_train_scaled.shape[1], y_train_scaled.shape[1])\n",
    "history = train_model(model, X_train_scaled, y_train_scaled, \n",
    "                     epochs=1000, patience=50, verbose=0)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled, verbose=0)\n",
    "r2_nn_, _ = evaluate_model(\"Neural Network\", y_test_scaled, y_pred, is_scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fce4c38e-4ae0-4b90-b3a5-2144b9885735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wide Neural Network Results (scaled):\n",
      "  Overall R2:  0.9527\n",
      "  Weighted R2: 0.9528\n"
     ]
    }
   ],
   "source": [
    "# train a wide model too:  [Input -> 128 -> 128 -> Output]\n",
    "model = build_nn_model(X_train_scaled.shape[1], y_train_scaled.shape[1], architecture=\"wide\")\n",
    "history = train_model(model, X_train_scaled, y_train_scaled,\n",
    "                      epochs=1000, patience=50, verbose=0)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled, verbose=0)\n",
    "r2_wide_nn, _ = evaluate_model(\"Wide Neural Network\", y_test_scaled, y_pred, is_scaled=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
